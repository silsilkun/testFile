"""
üèóÔ∏è Smart Tower Builder - Í∏¥Í∏â Ìå®Ïπò Î≤ÑÏ†Ñ
===========================================
ÏàòÏ†ï ÏÇ¨Ìï≠:
1. Î∏îÎ°ù Í≤ÄÏ∂ú ÌååÎùºÎØ∏ÌÑ∞ ÏôÑÌôî
2. Í∑∏Î¶¨Ìçº Í∞í ÏàòÏ†ï (550 ‚Üí 800)
3. depth_scale Î¨∏Ï†ú Ìï¥Í≤∞
4. ÎîîÎ≤ÑÍπÖ Ï∂úÎ†• Ï∂îÍ∞Ä
"""

import cv2
import rclpy
from rclpy.node import Node
import pyrealsense2 as rs
import numpy as np
import time
from sensor_msgs.msg import Image, CameraInfo
from cv_bridge import CvBridge, CvBridgeError
import message_filters
import DR_init
from tower_builder.gripper_drl_controller import GripperController
from dataclasses import dataclass, field
from typing import Optional, List, Tuple
from collections import deque
from enum import Enum

# Î°úÎ¥á ÏÑ§Ï†ï
ROBOT_ID = "dsr01"
ROBOT_MODEL = "e0509"
VELOCITY, ACC = 50, 50
DR_init.__dsr__id = ROBOT_ID
DR_init.__dsr__model = ROBOT_MODEL


class RobotState(Enum):
    IDLE = 0
    BLOCK_SELECTED = 1
    PICKING = 2
    PLACING = 3


@dataclass
class Block:
    bbox: Tuple[int, int, int, int]
    center_2d: Tuple[int, int]
    contour: np.ndarray = field(compare=False)
    rotated_box: np.ndarray = field(compare=False)
    area: float = 0.0
    aspect_ratio: float = 0.0
    solidity: float = 0.0
    center_3d: Optional[Tuple[float, float, float]] = None
    depth: float = 0.0
    real_width_mm: float = 0.0
    real_height_mm: float = 0.0
    size_class: str = "unknown"
    stability_score: int = 0
    last_seen_time: float = 0.0
    missing_frames: int = 0
    is_interpolated: bool = False


class BlockDetector:
    def __init__(self):
        # üî• Îçî Í¥ÄÎåÄÌïú ÏÑ§Ï†ï
        self.use_adaptive = True
        self.adaptive_block_size = 15  # 21 ‚Üí 15 (Îçî ÎØºÍ∞ê)
        self.adaptive_c = 1  # 2 ‚Üí 1 (Îçî Î∞ùÍ≤å)
        self.use_inv = True
        
        self.multi_blur = True
        self.blur_sizes = [(3, 3), (5, 5)]
        
        # üî• ÌÅ¨Í∏∞ ÌïÑÌÑ∞ Îçî ÏôÑÌôî
        self.min_area = 50  # 100 ‚Üí 50
        self.max_area = 15000  # 10000 ‚Üí 15000
        
        # üî• ROI ÏïΩÍ∞Ñ Ï°∞Ï†ï (ÌôîÎ©¥Ïóê ÎßûÍ≤å)
        self.roi_x = 150  # 190 ‚Üí 150
        self.roi_y = 120  # 140 ‚Üí 120
        self.roi_w = 350  # 230 ‚Üí 350 (Îçî ÎÑìÍ≤å)
        self.roi_h = 250  # 180 ‚Üí 250 (Îçî ÎÜíÍ≤å)
        
        # üî• ÌòïÌÉú ÌïÑÌÑ∞ ÏôÑÌôî
        self.min_aspect = 0.2
        self.max_aspect = 6.0  # 2.5 ‚Üí 6.0
        self.min_solidity = 0.3  # 0.6 ‚Üí 0.3
        
        self.min_depth = 0.1
        self.max_depth = 2.0
        
        self.small_thresh = 30
        self.medium_thresh = 50
        
        self.tracked_blocks = []
        self.max_track_distance = 50
        self.stability_threshold = 2  # 3 ‚Üí 2 (Îçî Îπ®Î¶¨ ÏïàÏ†ï)
        self.max_missing_frames = 5  # 3 ‚Üí 5 (Îçî Ïò§Îûò Ïú†ÏßÄ)
        
        self.binary_view = None
        
    def detect(self, frame, depth_image, intrinsics, depth_scale) -> List[Block]:
        current_time = time.time()
        all_candidates = []
        
        # Ï†ÅÏùëÌòï Ïù¥ÏßÑÌôîÎ°ú Í≤ÄÏ∂ú
        contours, binary = self._detect_with_adaptive(frame)
        self.binary_view = binary
        
        print(f"üîç Í≤ÄÏ∂úÎêú Ïú§Í≥ΩÏÑ† Ïàò: {len(contours)}")  # ÎîîÎ≤ÑÍπÖ
        
        for cnt in contours:
            candidate = self._process_contour(cnt, current_time)
            if candidate:
                all_candidates.append(candidate)
        
        print(f"‚úÖ ÌïÑÌÑ∞ ÌÜµÍ≥º ÌõÑÎ≥¥: {len(all_candidates)}")  # ÎîîÎ≤ÑÍπÖ
        
        unique_candidates = self._merge_duplicates(all_candidates)
        
        blocks = []
        for cand in unique_candidates:
            block = Block(
                bbox=cand['bbox'],
                center_2d=cand['center'],
                contour=cand['contour'],
                rotated_box=cand['rotated_box'],
                area=cand['area'],
                aspect_ratio=cand['aspect_ratio'],
                solidity=cand['solidity'],
                last_seen_time=current_time
            )
            
            cx, cy = cand['center']
            depth = self._get_depth_from_image(cx, cy, depth_image, depth_scale)
            
            print(f"  Î∏îÎ°ù Ï§ëÏã¨({cx}, {cy}): depth={depth*1000:.1f}mm")  # ÎîîÎ≤ÑÍπÖ
            
            if depth > 0:
                point_3d = rs.rs2_deproject_pixel_to_point(intrinsics, [cx, cy], depth)
                block.center_3d = point_3d
                block.depth = depth
                
                if self.min_depth < block.depth < self.max_depth:
                    real_w, real_h = self._calc_real_size(
                        cand['rect_w'], cand['rect_h'], depth, intrinsics
                    )
                    block.real_width_mm = real_w
                    block.real_height_mm = real_h
                    
                    avg = (real_w + real_h) / 2
                    if avg < self.small_thresh:
                        block.size_class = "small"
                    elif avg < self.medium_thresh:
                        block.size_class = "medium"
                    else:
                        block.size_class = "large"
            
            blocks.append(block)
        
        blocks = self._track_blocks(blocks, current_time)
        
        print(f"üéØ ÏµúÏ¢Ö Î∏îÎ°ù Ïàò: {len(blocks)}\n")  # ÎîîÎ≤ÑÍπÖ
        
        return blocks
    
    def _detect_with_adaptive(self, frame):
        roi = frame[self.roi_y:self.roi_y+self.roi_h, self.roi_x:self.roi_x+self.roi_w]
        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        
        all_contours = []
        
        for blur_size in self.blur_sizes:
            blurred = cv2.GaussianBlur(gray, blur_size, 0)
            
            binary = cv2.adaptiveThreshold(
                blurred, 255,
                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                cv2.THRESH_BINARY if self.use_inv else cv2.THRESH_BINARY_INV,
                self.adaptive_block_size,
                self.adaptive_c
            )
            
            if blur_size == (5, 5):
                kernel = np.ones((2, 2), np.uint8)
                binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)
            
            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            all_contours.extend(contours)
        
        return all_contours, binary
    
    def _process_contour(self, cnt, current_time):
        area = cv2.contourArea(cnt)
        is_small = area < 2000  # 1500 ‚Üí 2000
        
        if is_small:
            if area < 30:  # 50 ‚Üí 30
                return None
        else:
            if not (self.min_area < area < self.max_area):
                return None
        
        rect = cv2.minAreaRect(cnt)
        box = cv2.boxPoints(rect)
        box = np.intp(box)
        (_, _), (w, h), _ = rect
        
        if h == 0 or w == 0:
            return None
        
        aspect = max(w, h) / min(w, h)
        
        if is_small:
            if not (0.1 <= aspect <= 10.0):  # Îçî ÏôÑÌôî
                return None
        else:
            if not (self.min_aspect <= aspect <= self.max_aspect):
                return None
        
        hull = cv2.convexHull(cnt)
        hull_area = cv2.contourArea(hull)
        if hull_area == 0:
            return None
        
        solidity = area / hull_area
        min_sol = 0.2 if is_small else self.min_solidity  # 0.4 ‚Üí 0.2
        if solidity < min_sol:
            return None
        
        peri = cv2.arcLength(cnt, True)
        approx = cv2.approxPolyDP(cnt, 0.04 * peri, True)
        if not (3 <= len(approx) <= 12):  # 10 ‚Üí 12
            return None
        
        box_global = box.copy()
        box_global[:, 0] += self.roi_x
        box_global[:, 1] += self.roi_y
        cnt_global = cnt.copy()
        cnt_global[:, :, 0] += self.roi_x
        cnt_global[:, :, 1] += self.roi_y
        
        M = cv2.moments(cnt)
        if M["m00"] == 0:
            return None
        
        cx = int(M["m10"] / M["m00"]) + self.roi_x
        cy = int(M["m01"] / M["m00"]) + self.roi_y
        x, y, bw, bh = cv2.boundingRect(cnt)
        
        return {
            'bbox': (x + self.roi_x, y + self.roi_y, bw, bh),
            'center': (cx, cy),
            'contour': cnt_global,
            'rotated_box': box_global,
            'area': area,
            'aspect_ratio': aspect,
            'solidity': solidity,
            'rect_w': w,
            'rect_h': h,
            'is_small': is_small
        }
    
    def _merge_duplicates(self, candidates):
        if not candidates:
            return []
        
        unique = []
        used = [False] * len(candidates)
        
        for i, cand1 in enumerate(candidates):
            if used[i]:
                continue
            
            cx1, cy1 = cand1['center']
            group = [cand1]
            used[i] = True
            
            for j, cand2 in enumerate(candidates):
                if used[j]:
                    continue
                
                cx2, cy2 = cand2['center']
                dist = np.sqrt((cx1 - cx2)**2 + (cy1 - cy2)**2)
                
                if dist < 30:  # 25 ‚Üí 30
                    group.append(cand2)
                    used[j] = True
            
            best = max(group, key=lambda x: x['area'])
            unique.append(best)
        
        return unique
    
    def _track_blocks(self, current_blocks, current_time):
        if not self.tracked_blocks:
            for block in current_blocks:
                block.stability_score = 1
                block.missing_frames = 0
            self.tracked_blocks = current_blocks
            return current_blocks
        
        matched = [False] * len(current_blocks)
        updated_tracked = []
        
        for old_block in self.tracked_blocks:
            old_cx, old_cy = old_block.center_2d
            best_idx = -1
            best_dist = float('inf')
            
            for i, curr_block in enumerate(current_blocks):
                if matched[i]:
                    continue
                
                curr_cx, curr_cy = curr_block.center_2d
                dist = np.sqrt((old_cx - curr_cx)**2 + (old_cy - curr_cy)**2)
                
                if dist < self.max_track_distance and dist < best_dist:
                    best_dist = dist
                    best_idx = i
            
            if best_idx >= 0:
                matched[best_idx] = True
                current_blocks[best_idx].stability_score = min(old_block.stability_score + 1, 30)
                current_blocks[best_idx].missing_frames = 0
                current_blocks[best_idx].is_interpolated = False
                updated_tracked.append(current_blocks[best_idx])
            else:
                old_block.missing_frames += 1
                
                if old_block.missing_frames <= self.max_missing_frames:
                    old_block.is_interpolated = True
                    old_block.last_seen_time = current_time
                    old_block.stability_score = max(old_block.stability_score - 1, 0)
                    updated_tracked.append(old_block)
        
        for i, block in enumerate(current_blocks):
            if not matched[i]:
                block.stability_score = 1
                block.missing_frames = 0
                block.is_interpolated = False
                updated_tracked.append(block)
        
        self.tracked_blocks = updated_tracked
        return updated_tracked
    
    def _get_depth_from_image(self, x, y, depth_image, depth_scale):
        h, w = depth_image.shape
        x, y = int(x), int(y)
        
        if not (0 <= x < w and 0 <= y < h):
            return 0.0
        
        raw_depth = depth_image[y, x]
        depth_m = raw_depth * depth_scale
        
        if depth_m > 0.05:
            return depth_m
        
        sample_offsets = [
            (-5, 0), (5, 0), (0, -5), (0, 5),
            (-10, 0), (10, 0), (0, -10), (0, 10),
            (-15, 0), (15, 0), (0, -15), (0, 15),
        ]
        
        valid_depths = []
        for dx, dy in sample_offsets:
            sx, sy = x + dx, y + dy
            if 0 <= sx < w and 0 <= sy < h:
                raw = depth_image[sy, sx]
                d = raw * depth_scale
                if 0.05 < d < 3.0:
                    valid_depths.append(d)
        
        if valid_depths:
            valid_depths.sort()
            return valid_depths[len(valid_depths) // 2]
        
        return 0.0
    
    def _calc_real_size(self, w_px, h_px, depth, intrinsics):
        if depth <= 0:
            return 0, 0
        real_w = (w_px * depth * 1000) / intrinsics.fx
        real_h = (h_px * depth * 1000) / intrinsics.fy
        return real_w, real_h
    
    def find_block_at(self, blocks, x, y):
        for b in blocks:
            if b.is_interpolated:
                continue
            bx, by, bw, bh = b.bbox
            if bx <= x <= bx+bw and by <= y <= by+bh:
                return b
        return None


class RobotControllerNode(Node):
    def __init__(self):
        super().__init__("robot_controller_node")
        self.bridge = CvBridge()
        self.get_logger().info("ü§ñ Smart Tower Builder Ï¥àÍ∏∞Ìôî Ï§ë...")
        
        self.intrinsics = None
        self.depth_scale = 0.001
        self.latest_cv_color = None
        self.latest_cv_depth_mm = None
        
        self.detector = BlockDetector()
        self.detected_blocks = []
        
        self.robot_state = RobotState.IDLE
        self.selected_block = None
        self.target_position = None
        
        self.color_sub = message_filters.Subscriber(
            self, Image, '/camera/camera/color/image_raw'
        )
        self.depth_sub = message_filters.Subscriber(
            self, Image, '/camera/camera/aligned_depth_to_color/image_raw'
        )
        self.info_sub = message_filters.Subscriber(
            self, CameraInfo, '/camera/camera/aligned_depth_to_color/camera_info'
        )
        
        self.ts = message_filters.ApproximateTimeSynchronizer(
            [self.color_sub, self.depth_sub, self.info_sub],
            queue_size=10,
            slop=0.1
        )
        self.ts.registerCallback(self.synced_callback)
        
        self.gripper = None
        try:
            from DSR_ROBOT2 import wait
            self.gripper = GripperController(node=self, namespace=ROBOT_ID)
            self.get_logger().info("Waiting for service /dsr01/drl/drl_start...")
            wait(2)
            if not self.gripper.initialize():
                self.get_logger().error("‚ùå Gripper initialization failed")
                raise Exception("Gripper initialization failed")
            self.get_logger().info("‚úÖ Í∑∏Î¶¨Ìçº ÌôúÏÑ±Ìôî ÏôÑÎ£å")
            
            # üî• Í∑∏Î¶¨Ìçº Ï¥àÍ∏∞ ÏÉÅÌÉú ÌôïÏù∏
            self.gripper.move(50)  # ÏôÑÏ†ÑÌûà Ïó¥Í∏∞
            wait(1.0)
            print("üîß Í∑∏Î¶¨Ìçº Ï¥àÍ∏∞Ìôî: 50 (ÏôÑÏ†Ñ Ïó¥Î¶º)")
            
        except Exception as e:
            self.get_logger().error(f"Í∑∏Î¶¨Ìçº ÏÑ§Ï†ï Ïò§Î•ò: {e}")
        
        self.get_logger().info("‚úÖ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å!")
    
    def synced_callback(self, color_msg, depth_msg, info_msg):
        try:
            self.latest_cv_color = self.bridge.imgmsg_to_cv2(color_msg, "bgr8")
            self.latest_cv_depth_mm = self.bridge.imgmsg_to_cv2(depth_msg, "16UC1")
        except CvBridgeError as e:
            self.get_logger().error(f"CV Bridge Ïò§Î•ò: {e}")
            return
        
        if self.intrinsics is None:
            self.intrinsics = rs.intrinsics()
            self.intrinsics.width = info_msg.width
            self.intrinsics.height = info_msg.height
            self.intrinsics.ppx = info_msg.k[2]
            self.intrinsics.ppy = info_msg.k[5]
            self.intrinsics.fx = info_msg.k[0]
            self.intrinsics.fy = info_msg.k[4]
            
            if info_msg.distortion_model == 'plumb_bob':
                self.intrinsics.model = rs.distortion.brown_conrady
            else:
                self.intrinsics.model = rs.distortion.none
            
            self.intrinsics.coeffs = list(info_msg.d)
            self.depth_scale = 0.001
            
            self.get_logger().info("‚úÖ Ïπ¥Î©îÎùº ÌååÎùºÎØ∏ÌÑ∞ ÏàòÏã† ÏôÑÎ£å")
            print(f"üì∏ depth_scale: {self.depth_scale}")
        
        if self.latest_cv_color is not None and self.latest_cv_depth_mm is not None:
            self.detected_blocks = self.detector.detect(
                self.latest_cv_color,
                self.latest_cv_depth_mm,
                self.intrinsics,
                self.depth_scale
            )
    
    def mouse_callback(self, event, u, v, flags, param):
        if event != cv2.EVENT_LBUTTONDOWN:
            return
        
        if self.latest_cv_depth_mm is None or self.intrinsics is None:
            self.get_logger().warn("‚ö†Ô∏è Ïπ¥Î©îÎùº Îç∞Ïù¥ÌÑ∞ ÎåÄÍ∏∞ Ï§ë...")
            return
        
        if self.robot_state == RobotState.IDLE:
            block = self.detector.find_block_at(self.detected_blocks, u, v)
            
            if block and block.center_3d:
                self.selected_block = block
                self.robot_state = RobotState.BLOCK_SELECTED
                
                print("\n" + "="*60)
                print("üéØ Î∏îÎ°ù ÏÑ†ÌÉùÎê®!")
                print("="*60)
                cx, cy = block.center_2d
                print(f"  üìç Ï§ëÏã¨: ({cx}, {cy})")
                print(f"  üìè ÌÅ¨Í∏∞: {block.real_width_mm:.1f}x{block.real_height_mm:.1f}mm")
                print(f"  üè∑Ô∏è Î∂ÑÎ•ò: {block.size_class}")
                print(f"  üìê ÍπäÏù¥: {block.depth*1000:.1f}mm")
                print(f"\nüëâ Ïù¥Ï†ú ÎÇ¥Î†§ÎÜìÏùÑ ÏúÑÏπòÎ•º ÌÅ¥Î¶≠ÌïòÏÑ∏Ïöî!")
                print("="*60 + "\n")
            else:
                print("‚ö†Ô∏è Î∏îÎ°ùÏùÑ ÌÅ¥Î¶≠Ìï¥Ï£ºÏÑ∏Ïöî!")
        
        elif self.robot_state == RobotState.BLOCK_SELECTED:
            try:
                depth_mm = self.latest_cv_depth_mm[v, u]
            except IndexError:
                self.get_logger().warn(f"Ï¢åÌëú Î≤îÏúÑ Ï¥àÍ≥º: ({u}, {v})")
                return
            
            if depth_mm == 0:
                print("‚ö†Ô∏è ÍπäÏù¥Î•º Ï∏°Ï†ïÌï† Ïàò ÏóÜÏäµÎãàÎã§. Îã§Ïãú ÌÅ¥Î¶≠Ìï¥Ï£ºÏÑ∏Ïöî.")
                return
            
            depth_m = float(depth_mm) * self.depth_scale
            point_3d = rs.rs2_deproject_pixel_to_point(self.intrinsics, [u, v], depth_m)
            
            self.target_position = point_3d
            
            print("\n" + "="*60)
            print("‚úÖ Î™©Ìëú ÏúÑÏπò ÏÑ†ÌÉùÎê®!")
            print("="*60)
            print(f"  üìç ÌîΩÏÖÄ: ({u}, {v})")
            print(f"  üìê 3D: X={point_3d[0]*1000:.1f}, Y={point_3d[1]*1000:.1f}, Z={depth_m*1000:.1f}mm")
            print(f"\nü§ñ Î°úÎ¥á ÏûëÎèô ÏãúÏûë...")
            print("="*60 + "\n")
            
            self.execute_pick_and_place()
    
    def execute_pick_and_place(self):
        if not self.selected_block or not self.target_position:
            return
        
        try:
            from DSR_ROBOT2 import get_current_posx, movel, wait, movej
            from DR_common2 import posx, posj
            
            # ÌîΩ Ï¢åÌëú
            pick_rs_x = self.selected_block.center_3d[0] * 1000
            pick_rs_y = self.selected_block.center_3d[1] * 1000
            pick_rs_z = self.selected_block.depth * 1000
            
            pick_x = 685 + pick_rs_y
            pick_y = pick_rs_x + 20
            pick_z = max(811 - pick_rs_z, 150)
            
            # ÌîåÎ†àÏù¥Ïä§ Ï¢åÌëú
            place_rs_x = self.target_position[0] * 1000
            place_rs_y = self.target_position[1] * 1000
            place_rs_z = self.target_position[2] * 1000
            
            place_x = 685 + place_rs_y
            place_y = place_rs_x + 20
            place_z = max(811 - place_rs_z, 150)
            
            print(f"üéØ ÌîΩ ÏúÑÏπò: X={pick_x:.1f}, Y={pick_y:.1f}, Z={pick_z:.1f}")
            print(f"üéØ ÌîåÎ†àÏù¥Ïä§ ÏúÑÏπò: X={place_x:.1f}, Y={place_y:.1f}, Z={place_z:.1f}\n")
            
            current_pos = get_current_posx()[0]
            cur_Rx, cur_Ry, cur_Rz = current_pos[3], current_pos[4], current_pos[5]
            
            approach_lift = 50.0
            
            # === PICK ===
            print("üìå 1Îã®Í≥Ñ: Î∏îÎ°ù Ï†ëÍ∑º...")
            pick_up = [pick_x, pick_y, pick_z + approach_lift, cur_Rx, cur_Ry, cur_Rz]
            movel(posx(pick_up), vel=VELOCITY, acc=ACC)
            wait(0.5)
            
            print("üìå 2Îã®Í≥Ñ: Î∏îÎ°ù ÌïòÍ∞ï...")
            pick_at = [pick_x, pick_y, pick_z, cur_Rx, cur_Ry, cur_Rz]
            movel(posx(pick_at), vel=VELOCITY, acc=ACC)
            wait(0.5)
            
            # üî• Í∑∏Î¶¨Ìçº Í∞í ÏàòÏ†ï (550 ‚Üí 800)
            print("üìå 3Îã®Í≥Ñ: Í∑∏Î¶¨Ìçº Îã´Í∏∞ (ÏßëÍ∏∞)... [800]")
            self.gripper.move(800)  # üî• 550 ‚Üí 800
            wait(2.0)  # 1.5 ‚Üí 2.0 (Îçî Ïò§Îûò ÎåÄÍ∏∞)
            
            print("üìå 4Îã®Í≥Ñ: Î∏îÎ°ù Îì§Ïñ¥Ïò¨Î¶¨Í∏∞...")
            movel(posx(pick_up), vel=VELOCITY, acc=ACC)
            wait(0.5)
            
            # === PLACE ===
            print("üìå 5Îã®Í≥Ñ: Î™©Ìëú ÏúÑÏπò Ï†ëÍ∑º...")
            place_up = [place_x, place_y, place_z + approach_lift, cur_Rx, cur_Ry, cur_Rz]
            movel(posx(place_up), vel=VELOCITY, acc=ACC)
            wait(0.5)
            
            print("üìå 6Îã®Í≥Ñ: Î™©Ìëú ÏúÑÏπò ÌïòÍ∞ï...")
            place_at = [place_x, place_y, place_z, cur_Rx, cur_Ry, cur_Rz]
            movel(posx(place_at), vel=VELOCITY, acc=ACC)
            wait(0.5)
            
            # üî• Í∑∏Î¶¨Ìçº Í∞í ÏàòÏ†ï (100 ‚Üí 50)
            print("üìå 7Îã®Í≥Ñ: Í∑∏Î¶¨Ìçº Ïó¥Í∏∞ (ÎÜìÍ∏∞)... [50]")
            self.gripper.move(50)  # üî• 100 ‚Üí 50
            wait(1.5)  # 1.0 ‚Üí 1.5
            
            print("üìå 8Îã®Í≥Ñ: ÏÉÅÏäπ...")
            movel(posx(place_up), vel=VELOCITY, acc=ACC)
            wait(0.5)
            
            print("üìå 9Îã®Í≥Ñ: Ìôà Î≥µÍ∑Ä...")
            home_pose = posj(0, 0, 90, 0, 90, 0)
            movej(home_pose, VELOCITY, ACC)
            wait(1.0)
            
            print("\n‚úÖ ÌîΩÏï§ÌîåÎ†àÏù¥Ïä§ ÏôÑÎ£å!\n")
            
        except Exception as e:
            self.get_logger().error(f"‚ùå Î°úÎ¥á Ï†úÏñ¥ Ïò§Î•ò: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.selected_block = None
            self.target_position = None
            self.robot_state = RobotState.IDLE
            print("üí° Îã§Ïùå Î∏îÎ°ùÏùÑ ÏÑ†ÌÉùÌï¥Ï£ºÏÑ∏Ïöî!\n")
    
    def terminate_gripper(self):
        if self.gripper:
            self.gripper.terminate()


def main(args=None):
    rclpy.init(args=args)
    
    dsr_node = rclpy.create_node("dsr_node", namespace=ROBOT_ID)
    DR_init.__dsr__node = dsr_node
    
    try:
        from DSR_ROBOT2 import get_current_posx, movel, wait, movej
        from DR_common2 import posx, posj
    except ImportError as e:
        print(f"‚ùå DSR_ROBOT2 ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏ Ïã§Ìå®: {e}")
        rclpy.shutdown()
        exit(1)
    
    robot_controller = RobotControllerNode()
    
    cv2.namedWindow("Smart Tower Builder", cv2.WINDOW_NORMAL)
    cv2.resizeWindow("Smart Tower Builder", 640, 480)
    cv2.setMouseCallback("Smart Tower Builder", robot_controller.mouse_callback)
    
    print("\n" + "="*70)
    print("üèóÔ∏è  SMART TOWER BUILDER - Í∏¥Í∏â Ìå®Ïπò Î≤ÑÏ†Ñ")
    print("="*70)
    print("\nüîß ÏàòÏ†ï ÏÇ¨Ìï≠:")
    print("  - Î∏îÎ°ù Í≤ÄÏ∂ú ÌååÎùºÎØ∏ÌÑ∞ ÏôÑÌôî (Îçî ÎØºÍ∞êÌïòÍ≤å)")
    print("  - Í∑∏Î¶¨Ìçº Í∞í ÏàòÏ†ï: Îã´Í∏∞ 800, Ïó¥Í∏∞ 50")
    print("  - ROI ÌÅ¨Í∏∞ ÌôïÎåÄ")
    print("  - ÎîîÎ≤ÑÍπÖ Ï∂úÎ†• Ï∂îÍ∞Ä")
    print("\nüìã ÏÇ¨Ïö©Î≤ï:")
    print("  1Ô∏è‚É£  Ï≤´ Î≤àÏß∏ ÌÅ¥Î¶≠: ÏßëÏùÑ Î∏îÎ°ù ÏÑ†ÌÉù")
    print("  2Ô∏è‚É£  Îëê Î≤àÏß∏ ÌÅ¥Î¶≠: ÎÇ¥Î†§ÎÜìÏùÑ ÏúÑÏπò ÏÑ†ÌÉù")
    print("  ‚ùå ESC ÌÇ§: Ï¢ÖÎ£å")
    print("\n" + "="*70 + "\n")
    
    try:
        while rclpy.ok():
            rclpy.spin_once(robot_controller, timeout_sec=0.001)
            rclpy.spin_once(dsr_node, timeout_sec=0.001)
            
            if robot_controller.latest_cv_color is not None:
                display = robot_controller.latest_cv_color.copy()
                h, w, _ = display.shape
                
                d = robot_controller.detector
                cv2.rectangle(display, (d.roi_x, d.roi_y),
                            (d.roi_x + d.roi_w, d.roi_y + d.roi_h),
                            (0, 0, 255), 2)
                cv2.putText(display, "ROI", (d.roi_x, d.roi_y - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                
                for block in robot_controller.detected_blocks:
                    if block.is_interpolated:
                        continue
                    
                    is_selected = (block == robot_controller.selected_block)
                    is_stable = (block.stability_score >= d.stability_threshold)
                    
                    if is_selected:
                        color = (0, 255, 255)
                        thickness = 4
                    elif is_stable:
                        color = (0, 255, 0)
                        thickness = 2
                    else:
                        color = (0, 140, 255)
                        thickness = 2
                    
                    cv2.drawContours(display, [block.rotated_box], 0, color, thickness)
                    
                    cx, cy = block.center_2d
                    cv2.circle(display, (cx, cy), 5, (0, 0, 255), -1)
                    
                    if block.depth > 0:
                        txt = f"{block.size_class} [{block.stability_score}]"
                        cv2.putText(display, txt, (cx - 30, cy - 10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                
                status_text = {
                    RobotState.IDLE: "ÎåÄÍ∏∞: Î∏îÎ°ùÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
                    RobotState.BLOCK_SELECTED: "Î∏îÎ°ù ÏÑ†ÌÉùÎê®: Î™©Ìëú ÏúÑÏπò ÌÅ¥Î¶≠",
                    RobotState.PICKING: "ÌîΩ Ïã§Ìñâ Ï§ë...",
                    RobotState.PLACING: "ÌîåÎ†àÏù¥Ïä§ Ïã§Ìñâ Ï§ë..."
                }
                
                status = status_text[robot_controller.robot_state]
                cv2.putText(display, status, (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                stable_count = len([b for b in robot_controller.detected_blocks 
                                  if b.stability_score >= d.stability_threshold and not b.is_interpolated])
                cv2.putText(display, f"Blocks: {stable_count}", (10, 60),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                cv2.imshow("Smart Tower Builder", display)
            
            if cv2.waitKey(1) & 0xFF == 27:
                break
    
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Ctrl+CÎ°ú Ï¢ÖÎ£å...")
    except Exception as e:
        print(f"‚ùå Ïã§Ìñâ Ï§ë Ïò§Î•ò: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print("\nüõë ÌîÑÎ°úÍ∑∏Îû® Ï¢ÖÎ£å Ï§ë...")
        robot_controller.terminate_gripper()
        cv2.destroyAllWindows()
        robot_controller.destroy_node()
        dsr_node.destroy_node()
        rclpy.shutdown()
        print("‚úÖ Ï¢ÖÎ£å ÏôÑÎ£å\n")


if __name__ == '__main__':
    main()